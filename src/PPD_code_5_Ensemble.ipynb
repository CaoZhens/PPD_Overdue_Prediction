{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy.stats as st\n",
    "import sklearn.metrics as met\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as prep\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import hyperopt.pyll.stochastic\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "%matplotlib inline\n",
    "title = 'PPD'\n",
    "path = '../sources/data/PPD-First-Round-Data'\n",
    "icy = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49999, 389)\n",
      "0.0    0.926733\n",
      "1.0    0.073267\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pathofDataSaving = '../sources/deal/PPD-Data-Saving'\n",
    "irt = np.load('{}/{}_irt.npy'.format(pathofDataSaving, title))\n",
    "irv = np.load('{}/{}_irv.npy'.format(pathofDataSaving, title))\n",
    "dac = pd.read_hdf('{}/{}_dac.h5'.format(pathofDataSaving, title), key = 'dac')\n",
    "print dac.shape\n",
    "print dac.loc[irt, icy].value_counts()/dac.loc[irt, icy].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = dac.loc[:, [icy]]\n",
    "icx = list(set(dac.columns) - set([icy]))\n",
    "x = dac.loc[:, icx]\n",
    "x = x.apply(lambda x: x.fillna(x.median()),axis=0) # 使用中位数填充缺失值\n",
    "x = (x.rank(pct = True)-0.5/x.shape[0]).apply(st.norm.ppf) # 正态标准化\n",
    "#x = (x - x.mean())/x.std() # 中心归一标准化\n",
    "xt = x.loc[irt, :].values\n",
    "yt = y.loc[irt, :].values\n",
    "xv = x.loc[irv, :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# blending with LR & XGB\n",
    "from sklearn.model_selection import train_test_split\n",
    "xt_d1, xt_d2, yt_d1, yt_d2 = train_test_split(xt, yt, test_size=0.5, random_state=0, stratify=yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    0.926733\n",
      "1.0    0.073267\n",
      "dtype: float64\n",
      "0.0    0.926733\n",
      "1.0    0.073267\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print pd.Series(yt_d1.flatten()).value_counts() / yt_d1.shape[0]\n",
    "print pd.Series(yt_d2.flatten()).value_counts() / yt_d2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanghan/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from  xgboost import XGBClassifier\n",
    "models = [\n",
    "    ['lr', LogisticRegression(random_state=0, penalty='l2', C=0.003, class_weight='balanced', solver='sag')], \n",
    "    ['xgbc', XGBClassifier(seed=0, max_depth=3, learning_rate=0.05, subsample=0.9, min_child_weight=1.2, colsample_bytree=0.2, colsample_bylevel=1.0, gamma=0.3, reg_lambda=1.0)]\n",
    "]\n",
    "# 用d1训练模型\n",
    "blending_d2      = np.zeros((xt_d2.shape[0], len(models)))\n",
    "blending_test = np.zeros((xv.shape[0], len(models)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanghan/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.1 - lr - Training Time: 2.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanghan/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/fanghan/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.2 - xgbc - Training Time: 1.70 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "# for every base model\n",
    "for j, (name, model) in enumerate(models):\n",
    "    timeStart = time.time()\n",
    "    model.fit(xt_d1, yt_d1)\n",
    "    print 'No.{} - {} - Training Time: {:.2f} seconds'.format(j+1, name, time.time() - timeStart)\n",
    "    blending_d2[:, j]  = model.predict_proba(xt_d2)[:, 1]\n",
    "    blending_test[:, j] = model.predict_proba(xv)[:, 1]\n",
    "#     print 'base model %s: testSet auc Score = %.6f' % (name,  roc_auc_score(y_test, blending_test[:, j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc of No.1 model: 0.763548409627\n",
      "auc of No.2 model: 0.726069877076\n"
     ]
    }
   ],
   "source": [
    "# 融合前结果\n",
    "# blending_d2\n",
    "for i in range(len(models)):\n",
    "    print 'auc of No.%d model:'%(i+1), roc_auc_score(yt_d2, pd.DataFrame(blending_d2).iloc[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.27610632  1.77402898]]\n",
      "Linear stretch of predictions to [0,1]\n"
     ]
    }
   ],
   "source": [
    "# blending 融合\n",
    "clf = LogisticRegression()\n",
    "clf.fit(blending_d2, yt_d2)\n",
    "print clf.coef_\n",
    "clf_predict_prob = clf.predict_proba(blending_test)[:, 1]\n",
    "\n",
    "# 备注： 我们掌握了初赛轮具体结果，因此可以直接模拟线上得分\n",
    "\n",
    "print(\"Linear stretch of predictions to [0,1]\")\n",
    "clf_predict_prob_stretch = (clf_predict_prob - clf_predict_prob.min()) / (clf_predict_prob.max() - clf_predict_prob.min())\n",
    "\n",
    "# print 'blending result( no  stretch): testSet auc Score = %.6f' % (roc_auc_score(y_test, clf_predict_prob))\n",
    "# print 'blending result(with stretch): testSet auc Score = %.6f' % (roc_auc_score(y_test, clf_predict_prob_stretch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19999, 227)\n"
     ]
    }
   ],
   "source": [
    "# 从第二轮数据中模拟初赛线上打分\n",
    "def Del_string(xstr):\n",
    "    xstrc = xstr.strip().strip(u'市').strip(u'省')\n",
    "    if(xstrc == ''):\n",
    "        xstrc = np.nan\n",
    "    return(xstrc)\n",
    "\n",
    "newpath = '../sources/data/PPD-Second-Round-Data/first_round_test_data'\n",
    "par_csv = dict(index_col = 0, encoding = 'GB18030', parse_dates = [\"ListingInfo\"], na_values = [-1], \n",
    "               converters = dict(zip(*[[\"UserInfo_{}\".format(i) for i in [2,4,7,8,9,19,20]], [Del_string]*7])))\n",
    "\n",
    "dat_fr1_master = pd.read_csv('{}/Kesci_Master_9w_gbk_2.csv'.format(newpath), **par_csv)\n",
    "print dat_fr1_master.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19999,)\n",
      "0.767580446937\n",
      "0.767580446937\n"
     ]
    }
   ],
   "source": [
    "print clf_predict_prob.shape\n",
    "print roc_auc_score(dat_fr1_master['target'], clf_predict_prob)\n",
    "print roc_auc_score(dat_fr1_master['target'], clf_predict_prob_stretch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
